<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-04-12T00:25:47+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">John_date_river_side</title><subtitle>Hi, I'm Yuehan. I am putting some learning notes and project presentations here. Thanks for visiting! Drop me a message to my email address.</subtitle><entry><title type="html">Activation Functions: why we need it.</title><link href="http://localhost:4000/yuehan/notes/2019/04/12/Activation-functions.html" rel="alternate" type="text/html" title="Activation Functions: why we need it." /><published>2019-04-12T00:01:45+08:00</published><updated>2019-04-12T00:01:45+08:00</updated><id>http://localhost:4000/yuehan/notes/2019/04/12/Activation-functions</id><content type="html" xml:base="http://localhost:4000/yuehan/notes/2019/04/12/Activation-functions.html">&lt;p&gt;Why we need activation functions: if we only have linear neurons, then the network is no more than a linear regression function.&lt;/p&gt;

&lt;p&gt;Therefore, we need activition.&lt;/p&gt;

&lt;p&gt;Activation can also solve gradient vanishing and explosion.&lt;/p&gt;</content><author><name></name></author><summary type="html">Why we need activation functions: if we only have linear neurons, then the network is no more than a linear regression function.</summary></entry><entry><title type="html">Compute gradients in neural network.</title><link href="http://localhost:4000/yuehan/notes/2019/04/11/Gradients-in-neural-network.html" rel="alternate" type="text/html" title="Compute gradients in neural network." /><published>2019-04-11T13:57:45+08:00</published><updated>2019-04-11T13:57:45+08:00</updated><id>http://localhost:4000/yuehan/notes/2019/04/11/Gradients-in-neural-network</id><content type="html" xml:base="http://localhost:4000/yuehan/notes/2019/04/11/Gradients-in-neural-network.html">&lt;p&gt;How neural network update weights of its hidden units? This blog mainly refers from Andrew Ng’s course &lt;a href=&quot;https://www.coursera.org/learn/neural-networks-deep-learning/home/week/3&quot;&gt;Deep learning&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;do-the-prediction&quot;&gt;Do the prediction&lt;/h1&gt;
&lt;p&gt;Suppose we are constructing the simplest neural network that only has 1 layer of hidden neurons. It can be regarded as a logistic regression model. For one sample, given weights, we first compute the predicted $\bar{y}$, and the logloss $L$ caused by error between it and ground true:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z=w_1x_1+w_2x_2+b\\
\bar{y}=\sigma(z) = \frac{1}{1+e^{-z}}\\
L(\bar{y},y)=(1-y)log(\frac{1}{1-\bar{y}})+ylog(\frac{1}{\bar{y}})&lt;/script&gt;

&lt;h1 id=&quot;compute-gradients-to-update-weights&quot;&gt;Compute gradients to update weights&lt;/h1&gt;
&lt;p&gt;Hereto, $L$ shows the perforance of $w_1, w_2, b$, so we updates those weights(parameters) accordingly. We use gradient descent to update those parameters. Here is a general form of gradient descent, taking updating $w_1$ for instance:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{1,t+1}=w_{1,t}-\alpha \frac{\delta L}{\delta w_{1,t}},&lt;/script&gt;

&lt;p&gt;The $\alpha$ here is learning rate. So we have to compute $\frac{\delta L}{\delta w_1,t}$, we simply note it $\delta w_1$.
According to chain rule,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta w_1=x_1\cdot \frac{\delta L}{\delta z}\\
=x_1\cdot\frac{\delta L}{\delta \bar{y}}\cdot \frac{\delta \bar{y}}{\delta z}\\
=x_1\cdot (y-\bar{y})&lt;/script&gt;

&lt;p&gt;When we have $m$ examples, we just sum them up to obtain $\frac{1}{m}\sum_{i=1}^m\delta w_1^{(i)}$, because $L$ summing up across all samples is additive.&lt;/p&gt;

&lt;h1 id=&quot;back-propagation&quot;&gt;Back propagation&lt;/h1&gt;
&lt;p&gt;In the previous example, we only have one layer of weights to update. In a deeper network, the formula of $\delta w_1$ will incorptes weights of latter layers. In this case, we first update those latter weights (in terms of layer index), then update $w_1$, following the same methodology. This procedure is called back propagation.&lt;/p&gt;

&lt;p&gt;Back propagation leads to two problems regarding gradients. They are &lt;code class=&quot;highlighter-rouge&quot;&gt;gradient vanishing&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;gradient explosion&lt;/code&gt;. We will talk about using different activation funciton to solve those two problems in another blog.&lt;/p&gt;</content><author><name></name></author><summary type="html">How neural network update weights of its hidden units? This blog mainly refers from Andrew Ng’s course Deep learning. Do the prediction Suppose we are constructing the simplest neural network that only has 1 layer of hidden neurons. It can be regarded as a logistic regression model. For one sample, given weights, we first compute the predicted $\bar{y}$, and the logloss $L$ caused by error between it and ground true:</summary></entry></feed>